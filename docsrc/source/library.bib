@INPROCEEDINGS{Danner:2018,
  author={Danner, Gábor and Jelasity, Márk},
  booktitle={2018 IEEE 38th International Conference on Distributed Computing Systems (ICDCS)}, 
  title={Token Account Algorithms: The Best of the Proactive and Reactive Worlds}, 
  year={2018},
  volume={},
  number={},
  pages={885-895},
  doi={10.1109/ICDCS.2018.00090}
}


@article{Hegedus:2021,
	abstract = {Machine learning over distributed data stored by many clients has important applications in use cases where data privacy is a key concern or central data storage is not an option. Recently, federated learning was proposed to solve this problem. The assumption is that the data itself is not collected centrally. In a master--worker architecture, the workers perform machine learning over their own data and the master merely aggregates the resulting models without seeing any raw data, not unlike the parameter server approach. Gossip learning is a decentralized alternative to federated learning that does not require an aggregation server or indeed any central component. The natural hypothesis is that gossip learning is strictly less efficient than federated learning due to relying on a more basic infrastructure: only message passing and no cloud resources. In this empirical study, we examine this hypothesis and we present a systematic comparison of the two approaches. The experimental scenarios include a real churn trace collected over mobile phones, continuous and bursty communication patterns, different network sizes and different distributions of the training data over the devices. We also evaluate a number of additional techniques including a compression technique based on sampling, and token account based flow control for gossip learning. We examine the aggregated cost of machine learning in both approaches. Surprisingly, the best gossip variants perform comparably to the best federated learning variants overall, so they offer a fully decentralized alternative to federated learning.},
	author = {Istv{\'a}n Heged{\H u}s and G{\'a}bor Danner and M{\'a}rk Jelasity},
	doi = {https://doi.org/10.1016/j.jpdc.2020.10.006},
	issn = {0743-7315},
	journal = {Journal of Parallel and Distributed Computing},
	keywords = {Federated learning, Gossip learning, Decentralized machine learning},
	pages = {109-124},
	title = {Decentralized learning works: An empirical comparison of gossip learning and federated learning},
	volume = {148},
	year = {2021}
}

@article{Rosenblatt1958ThePA,
  title={The perceptron: a probabilistic model for information storage and organization in the brain.},
  author={Frank Rosenblatt},
  journal={Psychological review},
  year={1958},
  volume={65 6},
  pages={
          386-408
        }
}

@article{Ormandi:2013,
  author    = {R{\'{o}}bert Orm{\'{a}}ndi and
               Istv{\'{a}}n Heged{\"{u}}s and
               M{\'{a}}rk Jelasity},
  title     = {Gossip learning with linear models on fully distributed data},
  journal   = {Concurr. Comput. Pract. Exp.},
  volume    = {25},
  number    = {4},
  pages     = {556--571},
  year      = {2013},
  url       = {https://doi.org/10.1002/cpe.2858},
  doi       = {10.1002/cpe.2858},
  timestamp = {Sat, 31 Jul 2021 17:21:49 +0200},
  biburl    = {https://dblp.org/rec/journals/concurrency/OrmandiHJ13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inbook{Widrow:1988,
  author = {Widrow, Bernard and Hoff, Marcian E.},
  title = {Adaptive Switching Circuits},
  year = {1988},
  isbn = {0262010976},
  publisher = {MIT Press},
  address = {Cambridge, MA, USA},
  booktitle = {Neurocomputing: Foundations of Research},
  pages = {123–134},
  numpages = {12}
}

@INPROCEEDINGS{Giaretta:2019,  
  author={Giaretta, Lodovico and Girdzijauskas, Šarūnas},  
  booktitle={2019 IEEE International Conference on Big Data (Big Data)},   
  title={Gossip Learning: Off the Beaten Path},   
  year={2019},  
  volume={},  
  number={},  
  pages={1117-1124},  
  doi={10.1109/BigData47090.2019.9006216}
}

@inproceedings{Onoszko:2021,
  author={Noa Onoszko, Gustav Karlsson Olof Mogren, and Edvin Listo Zec},
  title={Decentralized federated learning of deep neural networks on non-iid data},
  booktitle={International Workshop on Federated Learning for User Privacy and Data Confidentiality 
  in Conjunction with ICML (FL-ICML'21)},
  year={2021}
}